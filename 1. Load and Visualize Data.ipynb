{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
   ],
   "source": [
    "key_pts_frame = pd.read_csv('/data/training_frames_keypoints.csv')\n",
    "\n",
    "n = 0\n",
    "image_name = key_pts_frame.iloc[n, 0]\n",
    "key_pts = key_pts_frame.iloc[n, 1:].as_matrix()\n",
    "key_pts = key_pts.astype('float').reshape(-1, 2)\n",
    "\n",
    "print('Image name: ', image_name)\n",
    "print('Landmarks shape: ', key_pts.shape)\n",
    "print('First 4 key pts: {}'.format(key_pts[:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
   ],
   "source": [
    "print('Number of images: ', key_pts_frame.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
   ],
   "source": [
    "def show_keypoints(image, key_pts):\n",
    "    plt.imshow(image)\n",
    "    plt.scatter(key_pts[:, 0], key_pts[:, 1], s=20, marker='.', c='m')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
   ],
   "source": [
    "n = 0\n",
    "image_name = key_pts_frame.iloc[n, 0]\n",
    "key_pts = key_pts_frame.iloc[n, 1:].as_matrix()\n",
    "key_pts = key_pts.astype('float').reshape(-1, 2)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "show_keypoints(mpimg.imread(os.path.join('/data/training/', image_name)), key_pts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class FacialKeypointsDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.key_pts_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.key_pts_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = os.path.join(self.root_dir,\n",
    "                                self.key_pts_frame.iloc[idx, 0])\n",
    "        \n",
    "        image = mpimg.imread(image_name)\n",
    "        if(image.shape[2] == 4):\n",
    "            image = image[:,:,0:3]\n",
    "        \n",
    "        key_pts = self.key_pts_frame.iloc[idx, 1:].as_matrix()\n",
    "        key_pts = key_pts.astype('float').reshape(-1, 2)\n",
    "        sample = {'image': image, 'keypoints': key_pts}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
   ],
   "source": [
    "face_dataset = FacialKeypointsDataset(csv_file='/data/training_frames_keypoints.csv',\n",
    "                                      root_dir='/data/training/')\n",
    "\n",
    "print('Length of dataset: ', len(face_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
   ],
   "source": [
    "num_to_display = 3\n",
    "\n",
    "for i in range(num_to_display):\n",
    "    \n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    rand_i = np.random.randint(0, len(face_dataset))\n",
    "    sample = face_dataset[rand_i]\n",
    "    print(i, sample['image'].shape, sample['keypoints'].shape)\n",
    "\n",
    "    ax = plt.subplot(1, num_to_display, i + 1)\n",
    "    ax.set_title('Sample #{}'.format(i))\n",
    "    show_keypoints(sample['image'], sample['keypoints'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "class Normalize(object):\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, key_pts = sample['image'], sample['keypoints']\n",
    "        \n",
    "        image_copy = np.copy(image)\n",
    "        key_pts_copy = np.copy(key_pts)\n",
    "        image_copy = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        image_copy=  image_copy/255.0\n",
    "        key_pts_copy = (key_pts_copy - 100)/50.0\n",
    "\n",
    "\n",
    "        return {'image': image_copy, 'keypoints': key_pts_copy}\n",
    "\n",
    "\n",
    "class Rescale(object):\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, key_pts = sample['image'], sample['keypoints']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = cv2.resize(image, (new_w, new_h))\n",
    "        key_pts = key_pts * [new_w / w, new_h / h]\n",
    "\n",
    "        return {'image': img, 'keypoints': key_pts}\n",
    "\n",
    "\n",
    "class RandomCrop(object):\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, key_pts = sample['image'], sample['keypoints']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "\n",
    "        image = image[top: top + new_h,\n",
    "                      left: left + new_w]\n",
    "\n",
    "        key_pts = key_pts - [left, top]\n",
    "\n",
    "        return {'image': image, 'keypoints': key_pts}\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        image, key_pts = sample['image'], sample['keypoints']\n",
    "        if(len(image.shape) == 2):\n",
    "            image = image.reshape(image.shape[0], image.shape[1], 1)\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'keypoints': torch.from_numpy(key_pts)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
   ],
   "source": [
    "rescale = Rescale(100)\n",
    "crop = RandomCrop(50)\n",
    "composed = transforms.Compose([Rescale(250),\n",
    "                               RandomCrop(224)])\n",
    "\n",
    "test_num = 500\n",
    "sample = face_dataset[test_num]\n",
    "\n",
    "fig = plt.figure()\n",
    "for i, tx in enumerate([rescale, crop, composed]):\n",
    "    transformed_sample = tx(sample)\n",
    "\n",
    "    ax = plt.subplot(1, 3, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title(type(tx).__name__)\n",
    "    show_keypoints(transformed_sample['image'], transformed_sample['keypoints'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
   ],
   "source": [
    "data_transform = transforms.Compose([Rescale(250),\n",
    "                                     RandomCrop(224),\n",
    "                                     Normalize(),\n",
    "                                     ToTensor()])\n",
    "transformed_dataset = FacialKeypointsDataset(csv_file='/data/training_frames_keypoints.csv',\n",
    "                                             root_dir='/data/training/',\n",
    "                                             transform=data_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
   ],
   "source": [
    "print('Number of images: ', len(transformed_dataset))\n",
    "\n",
    "for i in range(5):\n",
    "    sample = transformed_dataset[i]\n",
    "    print(i, sample['image'].size(), sample['keypoints'].size())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Ubuntu Linux)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}